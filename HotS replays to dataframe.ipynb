{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert multiple games to dataframe\n",
    "Will run through multiple games to produce a dataframe of common kill locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find files\n",
    "from os import listdir\n",
    "\n",
    "mypath = \"C:\\\\Users\\kevin\\Documents\\BTS\\KT_Work\\Heroes of the Storm\\\\replays\\Heroes lounge\\season 16 division 3\\goofy looking guys\"\n",
    "\n",
    "replay_files = listdir(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: heroprotocol in c:\\users\\kevin\\appdata\\roaming\\python\\python37\\site-packages (2.55.0.86938)\n",
      "Requirement already satisfied, skipping upgrade: mpyq>=0.2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from heroprotocol) (0.2.5)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.14.0 in c:\\users\\kevin\\appdata\\roaming\\python\\python37\\site-packages (from heroprotocol) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "# update heroprotocol with terminal\n",
    "!python -m pip install --upgrade heroprotocol --user --no-warn-script-location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\compat\\_optional.py:138: UserWarning: Pandas requires version '2.7.0' or newer of 'numexpr' (version '2.6.9' currently installed).\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# import function\n",
    "from replay_to_dataframe import *\n",
    "# import replay_to_dataframe as r2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0 of 24) 613e664d55853496476135.stormreplay parsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3162: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return asarray(a).ndim\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1 of 24) 613e665d074fd281805927.stormreplay parsed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:1684: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  self.obj[key] = infer_fill_value(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2 of 24) 613e66683955a856996939.stormreplay parsed\n",
      "(3 of 24) 614b8fed79580961488363.stormreplay parsed\n",
      "(4 of 24) 614b900117b07807174774.stormreplay parsed\n",
      "(5 of 24) 614b9019c8891299171987.stormreplay parsed\n",
      "(6 of 24) 6154ba4451a25185507045.stormreplay parsed\n",
      "(7 of 24) 6154ba5774c20194842551.stormreplay parsed\n",
      "(8 of 24) 615b611303473578598884.stormreplay parsed\n",
      "(9 of 24) 615b611d77166008120536.stormreplay parsed\n",
      "(10 of 24) 616882a35e971229109478.stormreplay parsed\n",
      "(11 of 24) 616882b9256e7260067818.stormreplay parsed\n",
      "(12 of 24) 6170751aa7b0d813705876.stormreplay parsed\n",
      "(13 of 24) 617075226991d523291605.stormreplay parsed\n",
      "(14 of 24) 617fe9a9c8205763594624.stormreplay parsed\n",
      "(15 of 24) 617fe9bc45ee0453184808.stormreplay parsed\n",
      "(16 of 24) 61883d002f552195323257.stormreplay parsed\n",
      "(17 of 24) 61883d112e4ac706910189.stormreplay parsed\n",
      "(18 of 24) 61883d22afbd4862592431.stormreplay parsed\n",
      "(19 of 24) 618ae54d1f4f7333916240.stormreplay parsed\n",
      "(20 of 24) 618ae55a31767810887320.stormreplay parsed\n",
      "(21 of 24) 618ae569063ae126628488.stormreplay parsed\n",
      "(22 of 24) 61941b0041d86323832367.stormreplay parsed\n",
      "(23 of 24) 61941b0d32a7a783262949.stormreplay parsed\n"
     ]
    }
   ],
   "source": [
    "replay_i = 1\n",
    "for replay_file in replay_files:\n",
    "# replay_file = replay_files[1]\n",
    "    !python -m heroprotocol --gameevents {'\"'+mypath+\"\\\\\"+replay_file+'\"'} > gameevents.txt\n",
    "    !python -m heroprotocol --messageevents {'\"'+mypath+\"\\\\\"+replay_file+'\"'} > messageevents.txt\n",
    "    !python -m heroprotocol --trackerevents {'\"'+mypath+\"\\\\\"+replay_file+'\"'} > trackerevents.txt\n",
    "    !python -m heroprotocol --attributeevents {'\"'+mypath+\"\\\\\"+replay_file+'\"'} > attributeevents.txt\n",
    "    !python -m heroprotocol --header {'\"'+mypath+\"\\\\\"+replay_file+'\"'} > header.txt\n",
    "    !python -m heroprotocol --details {'\"'+mypath+\"\\\\\"+replay_file+'\"'} > details.txt\n",
    "    !python -m heroprotocol --initdata {'\"'+mypath+\"\\\\\"+replay_file+'\"'} > initdata.txt\n",
    "\n",
    "    # parse files\n",
    "    data = ReplayData(near_distance = 10)\n",
    "\n",
    "    # set up export df\n",
    "    export_df = data.heroes_died_position.copy()\n",
    "\n",
    "    # add level of each team\n",
    "    exp_df = data.exp_event[[\"gameloop\", \"team\", \"level\"]].copy()\n",
    "    exp_df[\"team\"] = exp_df[\"team\"] - 1\n",
    "\n",
    "    export_df.at[:,\"team0_lvl\"] = 1\n",
    "    export_df.at[:,\"team1_lvl\"] = 1\n",
    "\n",
    "    export_df.at[:,\"all_players\"] = \"\"\n",
    "\n",
    "    for row_i in export_df.index:\n",
    "        gl = closest_gameloop(export_df.iloc[row_i].died_gameloop, list(map(int, exp_df.gameloop)))\n",
    "\n",
    "        if gl == -1:\n",
    "            pass\n",
    "        else:\n",
    "            export_df.at[row_i, \n",
    "                         [\"team0_lvl\", \"team1_lvl\", \"all_players\"]\n",
    "                        ] = [exp_df.loc[(exp_df['gameloop'] == gl) &\n",
    "                                        (exp_df['team'] == 0)]['level'].item(),\n",
    "                             exp_df.loc[(exp_df['gameloop'] == gl) &\n",
    "                                        (exp_df['team'] == 1)]['level'].item(),\n",
    "                             list(data.player_info.m_name)]\n",
    "\n",
    "        # add playerlist\n",
    "\n",
    "\n",
    "    # add map\n",
    "    export_df.at[:,\"map\"] = data.map\n",
    "\n",
    "    # add time played\n",
    "    export_df.at[:,\"timeUTC\"] = data.timeUTC\n",
    "\n",
    "    # add filename\n",
    "    export_df.at[:,\"replay_file\"] = replay_file.split(\".\")[0]\n",
    "\n",
    "\n",
    "\n",
    "    # export as csv\n",
    "    export_df.to_csv(\"./temp/\" + replay_file.split(\".\")[0] + \".csv\")\n",
    "\n",
    "    # building location\n",
    "    #     data.export_to_csv(\"building_position\",\"./temp/\" + data.map + \"_\" + replay_file.split(\".\")[0] + \".csv\")\n",
    "    data.building_position.to_csv(\"./building_position/\" + data.map + \"_\" + replay_file.split(\".\")[0] + \".csv\")\n",
    "\n",
    "    print(\"(\" + str(replay_i) + \" of \" + str(len(replay_files)) + \") \" + replay_file + \" parsed\")\n",
    "    replay_i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine all CSVs in a dataframe\n",
    "mypath_temp = \"C:\\\\Users\\kevin\\Documents\\BTS\\KT_Work\\Heroes of the Storm\\\\temp\"\n",
    "temp_replay_prased_files = listdir(mypath_temp)\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in temp_replay_prased_files:\n",
    "    df = pd.read_csv(mypath_temp+\"\\\\\"+filename, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "hero_died_all = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Dragon Shire', 'Towers of Doom', 'Garden of Terror', 'Drachengärten', 'Grabkammer der Spinnenkönigin', 'Cursed Hollow', 'Alterac Pass', 'Höllenschreine', 'Sky Temple', 'Infernal Shrines', 'Volskaya Foundry'}\n",
      "{'Dragon Shire', 'Tomb of the Spider Queen', 'Towers of Doom', 'Garden of Terror', 'Cursed Hollow', 'Alterac Pass', 'Sky Temple', 'Infernal Shrines', 'Volskaya Foundry'}\n"
     ]
    }
   ],
   "source": [
    "# translate map names to English\n",
    "print(set(hero_died_all.map))\n",
    "\n",
    "map_name_translation = {\n",
    "    'Drachengärten': 'Dragon Shire',\n",
    "    'Grabkammer der Spinnenkönigin': 'Tomb of the Spider Queen', \n",
    "    'Höllenschreine': 'Infernal Shrines'\n",
    "}\n",
    "\n",
    "hero_died_all.loc[:,\"map\"] = hero_died_all.map.replace(map_name_translation)\n",
    "\n",
    "print(set(hero_died_all.map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate map names for building position csv\n",
    "import os\n",
    "\n",
    "mypath_building_position = \"C:\\\\Users\\kevin\\Documents\\BTS\\KT_Work\\Heroes of the Storm\\\\building_position\"\n",
    "building_position_files = listdir(mypath_building_position)\n",
    "\n",
    "for filename in building_position_files:\n",
    "    map_name = filename.split(\"_\")[0]\n",
    "    replay_name = filename.split(\"_\")[1]\n",
    "    if map_name in map_name_translation.keys():\n",
    "        old_file_name = mypath_building_position + \"\\\\\" + filename\n",
    "        new_file_name = mypath_building_position + \"\\\\\" + map_name_translation[map_name] + \"_\" + replay_name\n",
    "        \n",
    "        os.rename(old_file_name, new_file_name)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine building positions\n",
    "building_position_files = listdir(mypath_building_position)\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in building_position_files:\n",
    "    df = pd.read_csv(mypath_building_position+\"\\\\\"+filename, header=0)\n",
    "    # add map name\n",
    "    df.at[:,\"map_name\"] = filename.split(\"_\")[0]\n",
    "    li.append(df)\n",
    "\n",
    "building_position_all = pd.concat(li, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The building position do not vary between replays but change on different maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill all_players with cell below\n",
    "hero_died_all.loc[:,\"all_players\"] = hero_died_all.all_players.bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output \n",
    "hero_died_all.to_csv(\"hero_died_all.csv\")\n",
    "building_position_all.to_csv(\"building_position_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
